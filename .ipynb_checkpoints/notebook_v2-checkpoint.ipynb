{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e52c307",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  \n",
    "!pip install -U -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b972032",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#from utils.utils import plot_results\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py:249\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    251\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#from utils.utils import plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b027d38",
   "metadata": {},
   "source": [
    "# Split data : train / val / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./raw/train.csv')\n",
    "test_df = pd.read_csv('./raw/test.csv')\n",
    "\n",
    "\n",
    "############ SAMPLE ##################################################\n",
    "train_df = pd.concat([train_df[train_df['class'] == 0].head(50) , train_df[train_df['class'] == 1].head(50) ,\n",
    "                     train_df[train_df['class'] == 2].head(50) , train_df[train_df['class'] == 3].head(50) ,\n",
    "                     train_df[train_df['class'] == 4].head(50) , train_df[train_df['class'] == 5].head(50),\n",
    "                    train_df[train_df['class'] == 6].head(50) ,\n",
    "                    train_df[train_df['class'] == 7].head(50) , train_df[train_df['class'] == 8].head(50) ,\n",
    "                     train_df[train_df['class'] == 9].head(50) , train_df[train_df['class'] == 10].head(50)\n",
    "                     ])\n",
    "\n",
    "test_df = test_df[:200]\n",
    "#########################################################################\n",
    " \n",
    "\n",
    "\n",
    "images_dir = './raw/images'\n",
    "train_dir = './dataset/train/images'\n",
    "val_dir = './dataset/val/images'\n",
    "test_dir = './dataset/test/images'\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "for image in train_df.image_path.unique():\n",
    "    shutil.copyfile(os.path.join(images_dir, image), os.path.join(train_dir, image))\n",
    "    \n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "for image in test_df.image_path.unique():\n",
    "    shutil.copyfile(os.path.join(images_dir, image), os.path.join(test_dir, image))\n",
    "\n",
    "if os.path.exists(val_dir):\n",
    "    shutil.rmtree(val_dir)\n",
    "\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "train_images = os.listdir(train_dir)\n",
    "val_images = train_images[len(train_images) - int(len(train_images) * 0.33) : ]\n",
    "for image in val_images:\n",
    "    shutil.move(os.path.join(train_dir, image), os.path.join(val_dir, image))\n",
    "\n",
    "val_df = train_df[train_df.image_path.isin(val_images)]\n",
    "train_df = train_df[~train_df.image_path.isin(val_images)]\n",
    "\n",
    "val_df = val_df.reset_index()\n",
    "train_df = train_df.reset_index()\n",
    "\n",
    "del val_df['index']\n",
    "del train_df['index']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59e233",
   "metadata": {},
   "source": [
    "# Get classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c346dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_df.drop_duplicates('name').sort_values(by='class').reset_index()\n",
    "classes = classes[['name', 'class']]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_context = '['\n",
    "for c in classes['name'].values:\n",
    "    classes_context =  classes_context +  \"'\" + c + \"', \"\n",
    "classes_context = classes_context[:-2]\n",
    "classes_context = classes_context + ']'\n",
    "classes_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2275f",
   "metadata": {},
   "source": [
    "# Convert dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd65fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dimensions(path=train_dir, df=train_df):\n",
    "    xs = [] \n",
    "    ys = [] \n",
    "    ws = [] \n",
    "    hs = []\n",
    "    heights = []\n",
    "    widths = []\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    for i in df.index:\n",
    "        image = Image.open(os.path.join(path,df.iloc[i].image_path))\n",
    "        height = image.height\n",
    "        width = image.width\n",
    "        \n",
    "        xmax = df.iloc[i].xmax #* 2\n",
    "        xmin = df.iloc[i].xmin #* 2\n",
    "        ymax = df.iloc[i].ymax #* 2\n",
    "        ymin = df.iloc[i].ymin #* 2\n",
    "        \n",
    "        x = ((xmax + xmin) / (2 * width))\n",
    "        y = ((ymax + ymin) / (2 * height))\n",
    "        w = (xmax - xmin) / width\n",
    "        h = (ymax - ymin) / height\n",
    "        \n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        ws.append(w)\n",
    "        hs.append(h)\n",
    "        \n",
    "        heights.append(height)\n",
    "        widths.append(width)\n",
    "    \n",
    "    return (xs, ys, ws, hs, widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('./raw/train.csv')\n",
    "train_df.ymin = train_df.ymin * 2\n",
    "train_df.ymax = train_df.ymax * 2\n",
    "train_df.xmin = train_df.xmin * 2\n",
    "train_df.xmax = train_df.xmax * 2\n",
    "new_training_dimensions = convert_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06915411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x'] = new_training_dimensions[0]\n",
    "train_df['y'] = new_training_dimensions[1]\n",
    "train_df['w'] = new_training_dimensions[2]\n",
    "train_df['h'] = new_training_dimensions[3]\n",
    "\n",
    "train_df['width'] = new_training_dimensions[4]\n",
    "train_df['height'] = new_training_dimensions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.ymin = val_df.ymin * 2\n",
    "val_df.ymax = val_df.ymax * 2\n",
    "val_df.xmin = val_df.xmin * 2\n",
    "val_df.xmax = val_df.xmax * 2\n",
    "new_val_dimensions = convert_dimensions(path=val_dir, df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['x'] = new_val_dimensions[0]\n",
    "val_df['y'] = new_val_dimensions[1]\n",
    "val_df['w'] = new_val_dimensions[2]\n",
    "val_df['h'] = new_val_dimensions[3]\n",
    "\n",
    "val_df['width'] = new_val_dimensions[4]\n",
    "val_df['height'] = new_val_dimensions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73710cf8",
   "metadata": {},
   "source": [
    "# Object detection (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_random(df=train_df, path=train_dir, count=1):\n",
    "    counter = 0 \n",
    "    df = df.sample(frac=1)\n",
    "    for image_path in df.image_path.unique():\n",
    "        select_df = df[df.image_path == image_path].reset_index()\n",
    "        del select_df['index']\n",
    "        \n",
    "        image = cv2.cvtColor(cv2.imread(os.path.join(path, image_path)), cv2.COLOR_BGR2RGB)\n",
    "        for i in select_df.index:\n",
    "            xmin = select_df.iloc[i].xmin #* 2\n",
    "            ymin = select_df.iloc[i].ymin #* 2\n",
    "            xmax = select_df.iloc[i].xmax #* 2\n",
    "            ymax = select_df.iloc[i].ymax #* 2\n",
    "            height = select_df.iloc[i].height\n",
    "            width = select_df.iloc[i].width\n",
    "            label = select_df.iloc[i]['name']\n",
    "            \n",
    "            print('class:' , select_df.iloc[i]['name'])\n",
    "            print('xmin:' , xmin)\n",
    "            print('ymin:' , ymin)\n",
    "            print('xmax:' , xmax)\n",
    "            print('ymax:' , ymax)\n",
    "            print('----------------------------')\n",
    "            \n",
    "            cv2.rectangle(image,\n",
    "                          (int(xmin) , int(ymin) ),\n",
    "                          (int(xmax) , int(ymax) ),\n",
    "                          (0,255,0), thickness=2)\n",
    "            \n",
    "            ((label_width, label_height), _) = cv2.getTextSize(label, fontFace=cv2.FONT_HERSHEY_PLAIN, \n",
    "            fontScale=1.75, thickness=2)\n",
    "            \n",
    "            cv2.rectangle(\n",
    "      image,\n",
    "          (int(xmin) , int(ymin)),\n",
    "          (int(xmin + label_width + label_width * 0.05), int(ymin + label_height + label_height * 0.25)),\n",
    "          color=(255, 0, 0),\n",
    "          thickness=cv2.FILLED\n",
    "        )\n",
    "            \n",
    "            cv2.putText(\n",
    "          image,\n",
    "          label,\n",
    "          org=(int(xmin), int(ymin + label_height + label_height * 0.25)), \n",
    "          fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "          fontScale=1.75,\n",
    "          color=(255, 255, 255),\n",
    "          thickness=2 )\n",
    "            \n",
    "            plt.imshow(image)\n",
    "        \n",
    "        counter = counter + 1\n",
    "        if count != None and count > 0 and counter >= count:\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6455a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detection_random(df=val_df, path=val_dir, count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff82ab4",
   "metadata": {},
   "source": [
    "# Label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df=train_df, path='./dataset/train/labels'):\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "    os.mkdir(path)\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    for i in df.index:\n",
    "        _class = df.iloc[i]['class']\n",
    "        file_name = df.iloc[i].image_path.split('.')[0] + '.txt'\n",
    "        x = df.iloc[i].x\n",
    "        y = df.iloc[i].y\n",
    "        w = df.iloc[i].w\n",
    "        h = df.iloc[i].h\n",
    "        \n",
    "        content = '{} {} {} {} {}\\n'\n",
    "        content = content.format(_class, x, y, w, h)\n",
    "        \n",
    "        f = open(os.path.join(path, file_name) , 'a')\n",
    "        f.write(content)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_labels(val_df, './dataset/val/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ab628",
   "metadata": {},
   "source": [
    "# Create config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config_text = \"\"\"train: {}\n",
    "val : {}\n",
    "nc: {}\n",
    "names: {}\n",
    "\"\"\"\n",
    "\n",
    "dataset_config_text = dataset_config_text.format('../' + train_dir, '../' + val_dir, classes['name'].nunique(), classes_context)\n",
    "\n",
    "f = open('./yolov5/dataset_config.yaml', 'w')\n",
    "f.write(dataset_config_text)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e6f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_text = \"\"\"# parameters\n",
    "nc: {}  # number of classes  # CHANGED HERE\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]\n",
    "\"\"\"\n",
    "\n",
    "model_config_text = model_config_text.format(classes['name'].nunique())\n",
    "\n",
    "f = open('./yolov5/model_config.yaml', 'w')\n",
    "f.write(model_config_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53743583",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c592efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5l.pt, cfg=, data=yolov5/dataset_config.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=768, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=16, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-70-g589edc7 Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (NVIDIA A100-SXM4-40GB, 40396MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
      "--------------------------------------------------------------------------\n",
      "WARNING: No preset parameters were found for the device that Open MPI\n",
      "detected:\n",
      "\n",
      "  Local host:            152-67-11-121\n",
      "  Device name:           mlx5_0\n",
      "  Device vendor ID:      0x02c9\n",
      "  Device vendor part ID: 4126\n",
      "\n",
      "Default device parameters will be used, which may result in lower\n",
      "performance.  You can edit any of the files specified by the\n",
      "btl_openib_device_param_files MCA parameter to set values for your\n",
      "device.\n",
      "\n",
      "NOTE: You can turn off this warning by setting the MCA parameter\n",
      "      btl_openib_warn_no_device_params_found to 0.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "No OpenFabrics connection schemes reported that they were able to be\n",
      "used on a specific port.  As such, the openib BTL (OpenFabrics\n",
      "support) will be disabled for this port.\n",
      "\n",
      "  Local host:           152-67-11-121\n",
      "  Local device:         mlx5_0\n",
      "  Local port:           1\n",
      "  CPCs attempted:       udcm\n",
      "--------------------------------------------------------------------------\n",
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     86160  models.yolo.Detect                      [11, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Model summary: 368 layers, 46192144 parameters, 46192144 gradients, 108.4 GFLOPs\n",
      "\n",
      "Transferred 607/613 items from yolov5/yolov5l.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ubuntu/dataset/train/labels.cache... 5276 images, 0 backgr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/00b5bf7dce31145b95ef3adb89a99b03.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        1.1]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/033ec532b0747efea95b9806301a5908.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/079c450d12649c8c9563e8c7f7e7193f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0583]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/0a4f38c94dd63cd8e5b9209dc9892146.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0302]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/0ac01d1803865c7ce0f88f9775de11a8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1406]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/0ea2c60055df54d117720f777a89fcb4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/137174a38b42b487f60dc806b3b98ce2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.349]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/16c94aad9cbe12f4cb731ba12bb39f33.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0093]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/1ebec92bfd65a987ec661963bb00fc65.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.026]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/2466a0b1fc6974a8f3a624c158bc4d08.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1875]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/2acbba0d2b1a3b294b4aa381afe1f9ca.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.8292      1.3259]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/2d660bb5f4a72e7f4edadb8774c8684e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2611      1.0407]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/30311043e69b23f8f0c57347aadab3fe.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0778      1.0019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/3212b4d8cf6512fe77c6ae7781d96d4e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.151]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/382a52988c6ea258f31b9ac3dac3422c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0519      1.0204]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/3ab05a2116cb0305869538ee1e15a931.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1521]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/3b58e2201d20c99374960cd5bc460c4c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0648]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/3e423949e29b36d5417e896553a11747.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.8198]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/414473abf9ba12e61b3942317c518a9a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.101]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/4396f5d6bb020e516053cf08a6887cce.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0365]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/4a75b6a76d6074940c2f6c02f4c619bc.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1646]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/528229659b31f33079d9b1c15923d64f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0019      1.2019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/53f160bc178eb0559c24801168415e17.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2313]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/54fcd25de32342d3a32d1d96adb3518a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.374]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/584113a4ceda9e5ce21573450ba4cafa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1271]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/589c7d413d6f544f13135bfba7108c04.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0074]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/5ba59eaae491b93fc28b7c60bd3aaaf7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3148      1.0056]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/65b259612090ddf276731738ce3c27bd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [        1.1]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/67af8340b0c2a30c22bd82b1ad92cb3e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3823]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/6bc5c51917ff8288d06ddde13487978a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.751]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/6c724b349edc9c52ec114cd9d14422cc.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0981      1.1074]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/6eef1c9eab21ad54c5b708a96f43f8f7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.6042      1.3722]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/6fad9974f4ac17a568b4821207affc8d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0479]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/6fc5dcd6562b210874a15ed2ee774938.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1229]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/7231db117e89e718901941d03c55c236.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0093]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/74110de526016e083116a9ffcb30f819.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0852]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/7685bb2f846758e5f529353e13c6394a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.226]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/7d9647b11f0c6446a8010cd223d85693.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1093]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/83fc281880965a8dad9715fb49347bde.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0426]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/85b98bfde6b5e51fbdba9699fe4f73da.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0969]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/8deaf21a5df59bd550a32e4cf977df21.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1531      1.1556]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/926a06f180036fdb92ac4fd63f2a3dec.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/94fefcbd102e6e6e64b09e341c261d40.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0219]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/98d1828ff412d6cdde56f9f9ff29e085.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2469      1.0685]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/9bcbc7471cab75af73975f9b22a00239.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/9cdedbfb6787d18b66c45e3b7f3c1a1a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2426]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/a15ef74becbbeac58e19f2f5ff456b07.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1948      1.3111]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/a267b15c74d2e395d2016a2b05971b2c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0241      1.0407]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/a669b7662e92ed829a47dc6228ac1b0c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2292         1.2]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/a7f95261f069f2299980eeac5fe19582.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/ad6320d0508d59a037febe99191aa0d2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1437]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/af01cf429a2b2effa428007777b46583.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0646]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/b42944b9d3f4ad67a5a49dadcb817948.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0823]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/b470f863c360b76ee060608a7022a9a3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/b4910285767283ef56086bb3534d080f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0074]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/b70b7975e2aa91b6f08a245a8b1fc472.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1781      1.1667]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/b892f6729d8387399f356ec58d2ba1e0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0427]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/c3983e130514b206c08f6c3eb2e3bba8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0148      1.0979]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/c44c2a5d6f4b37cc99d533b0d0db95c2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0542]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/c63d3070b519dc773c79ad5c147ec7ee.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.05        1.05]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/cba9618c645e88f60c438a3fa95cec98.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0815]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/cc01f935e9bf642a9b2bfed5ef0e141f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/ccf0d917c8f4fc152623af5d6d13b104.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0396]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/ccfb53aa4471e987138ebde5d6ef3897.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1729]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/cf37a57e8b2f4036c2b8d4ce071af247.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1333]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/d4f7e9d9de394088df4ebb5cb5d87b4a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5052]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/d92d709bec0ebab8e0eb195fcea2c182.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/de7958e40bc57be2d602959d68a00007.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.6156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/e1147eaf96d90e075b85a2243e9c27ea.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/ed7744651dea5e3822b47029d3498ddf.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.187      1.0852]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/f6b00342cfef5a9b77356003ca08e306.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/fc5006e83776b42f44f3ebf31612487e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0574]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/train/images/fdfe7e0aaa83fc43791cc03e694a654a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0204      1.0019]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.8GB ram): 100%|██████████| 5203/5203 [00:13<00:00, 393.\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/dataset/val/labels.cache... 2598 images, 0 background\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/026c5fd6fe0e64343e8ff1d6add9f88e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5698]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/08375747bbf8a35b2fa9d644ffd472c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.037]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/0a39d1bcea61bb0a20eba63f76c66eb3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0241]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/0c92987b3e7cbb325e67b35774be2b45.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1031]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/1c53dbbab5d22d9a3973f625fb2b4b86.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0981]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/1f04b1e254f1adf79975adf500bb4bc7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0185]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/2dc476af045aee0c0317402bfa4513fa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0312]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/31b6017b0cdcddc6e70ea7809eb53c32.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0704      1.0222]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/35426050b5eb788be2aee8bccf30a7b8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7125]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/3ad3c0fab444ec29bb7469f244850a9f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.013]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/512d0e2b895825c3e2382c28e97a9325.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1063]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/5e9d1dabe1be369a189c95958e6aa07a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.6094]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/68f2e79a99a4b0979f6c5d73f2cee1af.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0042]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/7502e2364648c7703d5ac1aebd6ced34.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.676]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/9f65a94b21d60cee9908ef5d29673c58.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0648]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/afbfb274162484157424ecd1c06b0abe.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4438]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/b1e4d6a657883d9fc0b3a145bfddae40.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1938]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/ba5cd4c6e6ef3c253644ac0d7d30d09f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0979]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/c1f9f00f71f1a08e6892db98bddd21f6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0019]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/d29b7f9823e520f5aaef91f2d41ee66e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2198]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/db9ddbff588d647a66dfb2d97c247a82.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0823]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/e5bd426eb5993b269cb1a96f414c6214.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0481]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/e6281de3bde14e6dd8c82ae576746013.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1219]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/e9c1014802dfc82b630aecb9ae70f482.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0969]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/f02f109edaf241e18eb74479a29c9ae9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0344]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/f1841082c9e919e2651136320cfde675.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2333]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/f839539c91d91e71b9b39c7b8584a8c5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0625]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/fcf65cbe5076a72ab26112c79885619c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1204]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/fee4a81f80654d1c66e984a0d018dd0d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0704]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/ubuntu/dataset/val/images/feef1ed3891571831b2021a33df19c81.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0583]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.4GB ram): 100%|██████████| 2568/2568 [00:11<00:00, 228.54\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.87 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to yolov5/runs/train/exp6/labels.jpg... \n",
      "Image sizes 768 train, 768 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train/exp6\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49      12.6G    0.07845    0.04974    0.03957         18        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.629      0.177     0.0894     0.0271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49      13.1G    0.06502    0.04132    0.01706         14        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491       0.57      0.278      0.183     0.0633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49      13.1G    0.06075    0.04014    0.01284         18        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.576      0.286      0.191     0.0682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49      13.1G    0.05766     0.0408    0.01224         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.468      0.295      0.186     0.0635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49      13.1G    0.05565    0.04078    0.01139         21        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491       0.55      0.314      0.272      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49      13.1G    0.05395    0.04035    0.01073         13        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.576      0.317      0.273      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49      13.1G    0.05285    0.03956   0.009523         14        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491        0.5       0.34      0.286      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49      13.1G    0.05179    0.03901   0.008973         32        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.555      0.356      0.311      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49      13.1G     0.0512    0.03859   0.008243         16        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.482      0.402      0.345      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49      13.1G     0.0506    0.03852   0.007686         28        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.484      0.404      0.338      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49      13.1G    0.04939    0.03767    0.00666          6        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.485       0.41      0.347      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49      13.1G    0.04852     0.0372   0.006464         16        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.495      0.391      0.341      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49      13.1G    0.04788    0.03693   0.006255         15        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.485      0.381       0.32      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49      13.1G    0.04724     0.0369   0.005848         16        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.491      0.395      0.348      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49      13.1G    0.04697    0.03634   0.005559         26        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.491        0.4      0.353      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49      13.1G    0.04636    0.03596   0.005214          8        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.531      0.423      0.376      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49      13.1G    0.04585    0.03517   0.005081          8        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.506      0.435      0.371      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49      13.1G    0.04523    0.03457   0.004686         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.486      0.367      0.335      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49      13.1G    0.04457    0.03445    0.00443          6        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.524      0.443      0.372      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49      13.1G    0.04409    0.03454   0.004516         15        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.517      0.429      0.374       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49      13.1G    0.04347    0.03341   0.003993         19        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.544      0.444      0.403       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49      13.1G    0.04288    0.03327   0.003968         25        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.472      0.426      0.356      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49      13.1G    0.04235    0.03251   0.003907          8        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.506       0.44      0.372      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49      13.1G    0.04186     0.0323   0.003512         12        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.541       0.43      0.378      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49      13.1G    0.04108    0.03162   0.003291         17        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491       0.56        0.4      0.364      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49      13.1G    0.04108    0.03144     0.0032         12        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.514      0.439      0.371      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49      13.1G    0.04047      0.031   0.003088         11        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.559      0.426      0.373      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49      13.1G    0.03953    0.03069   0.002881          9        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.531      0.417       0.37      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49      13.1G    0.03918    0.03071   0.002751         16        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.538       0.45      0.383      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49      13.1G    0.03869    0.03018   0.002878         13        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.546      0.433      0.389      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49      13.1G    0.03805    0.02922   0.002821          9        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.573      0.413       0.38      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49      13.1G    0.03784    0.02909   0.002707          7        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.563      0.415      0.375      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49      13.1G    0.03673    0.02854   0.002471          5        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.584       0.43      0.391      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49      13.1G    0.03654    0.02874   0.002497         11        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491       0.55      0.446      0.382      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49      13.1G    0.03576    0.02814   0.002134         18        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491       0.55      0.435      0.376      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49      13.1G    0.03514     0.0275   0.002294         15        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.551      0.434      0.378      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49      13.1G    0.03471    0.02737    0.00218          9        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.567      0.427      0.381      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49      13.1G    0.03426    0.02705   0.002162         35        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.591      0.406      0.376      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49      13.1G    0.03366    0.02639   0.001994          8        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.598      0.426      0.381      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49      13.1G    0.03308    0.02594   0.001937         15        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.553      0.438      0.382      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49      13.1G    0.03252    0.02537   0.001835         12        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.546      0.427      0.368      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49      13.1G    0.03199    0.02574    0.00185         20        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.574       0.42      0.375      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49      13.1G    0.03114    0.02479   0.001863         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.563      0.427      0.375      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49      13.1G    0.03082     0.0247   0.001677         18        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.582      0.429      0.387       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49      13.1G    0.03028    0.02408    0.00164         19        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.558      0.431      0.376      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49      13.1G    0.02957     0.0235   0.001568         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.568      0.429      0.385      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49      13.1G    0.02937    0.02334   0.001613         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.573      0.418      0.378      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49      13.1G    0.02891    0.02329   0.001537         13        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.595      0.413      0.388      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49      13.1G    0.02833    0.02261   0.001394         10        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.596      0.403      0.385      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49      13.1G    0.02803    0.02264   0.001428         19        768: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.584      0.417      0.381      0.159\n",
      "\n",
      "50 epochs completed in 0.941 hours.\n",
      "Optimizer stripped from yolov5/runs/train/exp6/weights/last.pt, 92.9MB\n",
      "Optimizer stripped from yolov5/runs/train/exp6/weights/best.pt, 92.9MB\n",
      "\n",
      "Validating yolov5/runs/train/exp6/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46162128 parameters, 0 gradients, 107.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       2568       6491      0.543      0.444      0.403       0.16\n",
      "              GRAFFITI       2568        402       0.66      0.642      0.656      0.297\n",
      "         FADED_SIGNAGE       2568         40      0.441      0.525      0.422      0.121\n",
      "              POTHOLES       2568        893      0.424      0.295        0.3     0.0999\n",
      "               GARBAGE       2568       2780      0.528      0.555      0.507      0.184\n",
      "     CONSTRUCTION_ROAD       2568        853      0.635      0.692      0.623      0.218\n",
      "        BROKEN_SIGNAGE       2568         31      0.292      0.194      0.184      0.102\n",
      "         BAD_BILLBOARD       2568          1          1          0          0          0\n",
      "          SAND_ON_ROAD       2568        480      0.603       0.61      0.577      0.268\n",
      "      CLUTTER_SIDEWALK       2568        248      0.466       0.44      0.338      0.129\n",
      "         UNKEPT_FACADE       2568        714      0.653      0.704      0.659       0.27\n",
      "       BAD_STREETLIGHT       2568         49      0.275      0.224      0.171     0.0747\n",
      "Results saved to \u001b[1myolov5/runs/train/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/train.py --img 768  --epochs 50 --data yolov5/dataset_config.yaml --weights yolov5/yolov5l.pt --cache --workers 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21dbce",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/detect.py --weights yolov5/runs/train/l/weights/best.pt --img 640 --conf 0.4 --source dataset/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23169c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d12d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4dd5fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/train/exp6/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../dataset/test/2e2300be77fb56a90d61add02e2a862d.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('yolov5', 'custom', path='./runs/train/exp6/weights/best.pt', source='local') \n",
    "img = '../dataset/test/2e2300be77fb56a90d61add02e2a862d.jpg'\n",
    "# Inference\n",
    "results = model(img)\n",
    "# Results, change the flowing to: results.show()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d0422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
